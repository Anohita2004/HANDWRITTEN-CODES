{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a0da6b6",
   "metadata": {},
   "source": [
    "# MULTIPLE LINEAR REGRESSION USING SKLEARN LIBRARY:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ede05fd",
   "metadata": {},
   "source": [
    "### STEP 1:Importing the necessary libraries for the dataset.Also importing the diabetes dataset from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd14698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a7a2e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ada39be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
       "         0.01990749, -0.01764613],\n",
       "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
       "        -0.06833155, -0.09220405],\n",
       "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
       "         0.00286131, -0.02593034],\n",
       "       ...,\n",
       "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
       "        -0.04688253,  0.01549073],\n",
       "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
       "         0.04452873, -0.02593034],\n",
       "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
       "        -0.00422151,  0.00306441]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "43e224f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d5960138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
       "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
       "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
       "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
       "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
       "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
       "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
       "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
       "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
       "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
       "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
       "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
       "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
       "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
       "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
       "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
       "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
       "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
       "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
       "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
       "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
       "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
       "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
       "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
       "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
       "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
       "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
       "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
       "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
       "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
       "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
       "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
       "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
       "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
       "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
       "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
       "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
       "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
       "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
       "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
       "       220.,  57.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4a04396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa63d8",
   "metadata": {},
   "source": [
    "### STEP2:Importing train test split and splitting the data into training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f55887c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3323a2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 10)<- is the training dataset shape and (89, 10)<- is the test data\n"
     ]
    }
   ],
   "source": [
    "print(f'{X_train.shape}<- is the training dataset shape and {X_test.shape}<- is the test data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34815925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353,)<- is the y training dataset shape and (89,)<- is the test data\n"
     ]
    }
   ],
   "source": [
    "print(f'{y_train.shape}<- is the y training dataset shape and {y_test.shape}<- is the test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd86aaa",
   "metadata": {},
   "source": [
    "### STEP 3:Importing the Linear Regression module from sklearn to implement it on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c43507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "955c146b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model into the linear regression model.\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "508f4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the value of y prediction values.\n",
    "y_pred=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a84148e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([247.20145833, 172.85994688,  76.8458742 , 193.00059702,\n",
       "       100.28696634, 168.37456091,  81.66639595, 218.82803362,\n",
       "       196.55728665, 184.67533075, 177.90994595, 153.53366721,\n",
       "       176.99111659, 229.48110415,  57.08476304, 196.58324018,\n",
       "       255.58929965,  85.85605139, 202.0486218 ,  69.22989475,\n",
       "       169.1304953 , 193.37382886, 164.42997134, 155.98284129,\n",
       "       159.85889722, 103.83787347,  98.99302305, 176.26522999,\n",
       "       165.45962337, 169.52257328, 153.84090734,  83.50739012,\n",
       "       137.50959329, 145.84520909, 108.60605477, 148.85733126,\n",
       "       134.8360016 , 237.90585502, 260.53340411, 126.15200694,\n",
       "       217.58301627, 228.76174393, 163.00905582, 110.13793169,\n",
       "       121.71002437, 148.68182957, 202.90692126, 139.91700144,\n",
       "       143.84493373,  93.54174033,  87.53441565,  77.05966895,\n",
       "       103.00000769,  97.03831966, 148.52059932, 131.67009586,\n",
       "        32.11306683,  75.45837207,  68.0720316 , 253.5080215 ,\n",
       "       113.69571782, 204.10508503, 191.18020679, 207.91051875,\n",
       "       182.57179173, 107.10579626, 255.28656647, 153.11062485,\n",
       "       144.28664246,  53.5599543 , 204.64202123, 249.67793876,\n",
       "       187.69398868, 224.35938319,  74.38781598, 214.99982065,\n",
       "       161.85053708, 199.28075541, 119.0979999 ,  52.52612693,\n",
       "       155.53919145, 235.81811535, 150.88396809,  72.97541845,\n",
       "       235.54889981, 191.54409683, 174.08533869,  43.50199496,\n",
       "       188.17830737])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d127e76",
   "metadata": {},
   "source": [
    "### STEP 4:Importing r2 score from sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fccf5f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5d63c691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5505453765626078"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66240cb5",
   "metadata": {},
   "source": [
    "### STEP 5:Now we obtain the values for the coefficient that is the value of co efficients and the intercept is the value for offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4f0891dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient beta0 is: -17.23220816374574\n",
      "The coefficient beta1 is: -225.20253652191286\n",
      "The coefficient beta2 is: 465.9861731154056\n",
      "The coefficient beta3 is: 359.8697513713534\n",
      "The coefficient beta4 is: -752.0345792657871\n",
      "The coefficient beta5 is: 513.2418483109903\n",
      "The coefficient beta6 is: 75.51984952578034\n",
      "The coefficient beta7 is: 133.4823173066623\n",
      "The coefficient beta8 is: 779.0967630578413\n",
      "The coefficient beta9 is: 23.558170458006956\n"
     ]
    }
   ],
   "source": [
    "for d, coef in enumerate(lr.coef_):\n",
    "    print(f'The coefficient beta{d} is: {coef}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1420529d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.4989268933548"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e0b5cd",
   "metadata": {},
   "source": [
    "# MAKING A MANUAL MULTIPLE LINEAR REGRESSION CLASS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff973c",
   "metadata": {},
   "source": [
    "### STEP 1:Formation of class that contains functions called fit and predict and two values coeffficient and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "08f84ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlr:\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        import numpy as np\n",
    "        X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "        # Calculation of coefficients\n",
    "        beta_values = np.linalg.inv(np.dot(X_train.T, X_train)).dot(X_train.T).dot(y_train)\n",
    "        self.intercept_ = beta_values[0]\n",
    "        self.coef_ = beta_values[1:]\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        import numpy as np\n",
    "        X_test = np.insert(X_test, 0, 1, axis=1)\n",
    "        predictions = np.dot(X_test, np.concatenate(([self.intercept_], self.coef_)))\n",
    "        return predictions\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ffb16",
   "metadata": {},
   "source": [
    "### STEP 2:Fitting the same training and testing dataset to our multiple regression class or model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "daa2cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple=mlr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c086596",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7f1e59f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([247.20145833, 172.85994688,  76.8458742 , 193.00059702,\n",
       "       100.28696634, 168.37456091,  81.66639595, 218.82803362,\n",
       "       196.55728665, 184.67533075, 177.90994595, 153.53366721,\n",
       "       176.99111659, 229.48110415,  57.08476304, 196.58324018,\n",
       "       255.58929965,  85.85605139, 202.0486218 ,  69.22989475,\n",
       "       169.1304953 , 193.37382886, 164.42997134, 155.98284129,\n",
       "       159.85889722, 103.83787347,  98.99302305, 176.26522999,\n",
       "       165.45962337, 169.52257328, 153.84090734,  83.50739012,\n",
       "       137.50959329, 145.84520909, 108.60605477, 148.85733126,\n",
       "       134.8360016 , 237.90585502, 260.53340411, 126.15200694,\n",
       "       217.58301627, 228.76174393, 163.00905582, 110.13793169,\n",
       "       121.71002437, 148.68182957, 202.90692126, 139.91700144,\n",
       "       143.84493373,  93.54174033,  87.53441565,  77.05966895,\n",
       "       103.00000769,  97.03831966, 148.52059932, 131.67009586,\n",
       "        32.11306683,  75.45837207,  68.0720316 , 253.5080215 ,\n",
       "       113.69571782, 204.10508503, 191.18020679, 207.91051875,\n",
       "       182.57179173, 107.10579626, 255.28656647, 153.11062485,\n",
       "       144.28664246,  53.5599543 , 204.64202123, 249.67793876,\n",
       "       187.69398868, 224.35938319,  74.38781598, 214.99982065,\n",
       "       161.85053708, 199.28075541, 119.0979999 ,  52.52612693,\n",
       "       155.53919145, 235.81811535, 150.88396809,  72.97541845,\n",
       "       235.54889981, 191.54409683, 174.08533869,  43.50199496,\n",
       "       188.17830737])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebac2009",
   "metadata": {},
   "source": [
    "### STEP 3:Calculating the value of the intercept and the coefficients of our manual model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "83a4d46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficient beta0 is: -17.23220816374574\n",
      "The coefficient beta1 is: -225.20253652191286\n",
      "The coefficient beta2 is: 465.9861731154056\n",
      "The coefficient beta3 is: 359.8697513713534\n",
      "The coefficient beta4 is: -752.0345792657871\n",
      "The coefficient beta5 is: 513.2418483109903\n",
      "The coefficient beta6 is: 75.51984952578034\n",
      "The coefficient beta7 is: 133.4823173066623\n",
      "The coefficient beta8 is: 779.0967630578413\n",
      "The coefficient beta9 is: 23.558170458006956\n"
     ]
    }
   ],
   "source": [
    "for d, coef in enumerate(lr.coef_):\n",
    "    print(f'The coefficient beta{d} is: {coef}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e52ca3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151.4989268933548"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple.intercept_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa3609a",
   "metadata": {},
   "source": [
    "# CONCLUSION:\n",
    "Hence we conclude from implementing our own model for multiple linear regression and the linear regression from sklearn library that the vakues of the offset i.e. intercept and the value of the coefficients are exactly the same.\n",
    "We have used the OLS(Ordinary Least Square)Method to derive the formulas and it is clearly derivable that the sklearn library uses the same for the linear regression model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
